![](dash_visualization/assets/team_logo.PNG)


<p align="center">
  <img width="460" height="300" src="dash_visualization/assets/team_logo.PNG">
</p>

Mappe struktur:
DL -> Deep learing kode
ML -> Machine learing kode
PowerBI -> visualiseringer 
Starschema_sosial -> sql kode for star schema for sosiale veriabler 
dash_visualization -> dash visualisering
database -> volum for postgres i docker
databaseconnection -> er vår å koble til og sende data fra api til databasen (gp_makasa)
sql -> sql koden for ETL delen
google colab -> koden vi brukte for ML og DL i colab
text_documents -> er beskrivelse av dataen vi hentet fra API
main.py -> programmet som gir deg mulighet til å laste ned dataen i CSV og legge til dataen til databasen.
requirements.txt -> er beskrivelse av alle pakkene og dens versjon vi har brukt i prosjektet. 


# Bruke programmet

- install requirements.txt
>>> pip install -r requirements.txt

For nedlasting av data start programmet main.py. 
>>> python main.py

## starte programmet
![](dash_visualization/assets/run_main_program.PNG)

## legge til data til databasen
![](dash_visualization/assets/run_main_program1.PNG)


